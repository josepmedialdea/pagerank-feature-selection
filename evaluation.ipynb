{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9961dc65-21e9-4edd-89ac-1022290a7f6b",
   "metadata": {},
   "source": [
    "# Page Rank Feature Selection algorithm evaluation\n",
    "\n",
    "This notebook contains all the experiments that have been done to test the performance of the PageRank Feature Selection algorithm. It is part of the report of the final thesis of Josep Medialdea."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9692b7f-5f68-403f-805a-0d5d771e5486",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8001ed5-2a53-4c4a-96ab-38d703f41b37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from prfs.feature_selection import PageRankFeatureSelector\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cdf9cf-d0a6-4b30-abb0-a7036cbdb209",
   "metadata": {},
   "source": [
    "# Dataset initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9af6eb5-60b2-4ff5-9930-c1d2f14ea997",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_name = 'dice1'\n",
    "drop_columns = []\n",
    "\n",
    "dataset = pd.read_csv(f'datasets/{dataset_name}.csv').drop(columns=drop_columns)\n",
    "features = dataset.iloc[:, :-1]\n",
    "target = dataset.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536d678f-0b33-494d-be74-77eba5f3ce34",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e7b34a-0225-4e3a-a644-815d69ad306c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prfs_params = {\n",
    "    'graph':  'feature',\n",
    "    'alpha':  'accuracy',\n",
    "    'beta':   'accuracy',\n",
    "    'weight':  0.5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e886bdd-f890-4d06-afde-0fa5b825670e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prfs = PageRankFeatureSelector(**prfs_params)\n",
    "t1 = time.perf_counter_ns()\n",
    "prfs.fit(features, target)\n",
    "t2 = time.perf_counter_ns()\n",
    "print(f'Elapsed time: {t2 - t1} ns')\n",
    "print(prfs.ranking())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb41bcbc-c81b-49eb-b3aa-b6fc537d2f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_relevant = [0]\n",
    "n_redundant = [0]\n",
    "n_irrelevant = [0]\n",
    "\n",
    "for i in range(len(features.columns)):\n",
    "    rel = 0\n",
    "    red = 0\n",
    "    irr = 0\n",
    "    for feature_name in prfs.select(i + 1):\n",
    "        if 'dice' in feature_name or ('relevant' in feature_name and not 'irrelevant' in feature_name):\n",
    "            rel += 1\n",
    "        elif 'sum' in feature_name or 'redundant' in feature_name:\n",
    "            red += 1\n",
    "        else:\n",
    "            irr += 1\n",
    "    n_relevant.append(rel)\n",
    "    n_redundant.append(red)\n",
    "    n_irrelevant.append(irr)\n",
    "\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "plt.xlabel(r'\\textbf{Number of features}',fontsize=16)\n",
    "plt.ylabel(r'\\textbf{Feature type count}',fontsize=16)\n",
    "plt.title(f'{dataset_name} dataset', fontsize=16)\n",
    "plt.plot(range(0, len(n_irrelevant)), n_irrelevant, marker='s', color='r', label='Irrelevant')\n",
    "plt.plot(range(0, len(n_redundant)), n_redundant, marker='s', color='b', label='Redundant')\n",
    "plt.plot(range(0, len(n_relevant)), n_relevant, marker='s', color='g', label='Relevant')\n",
    "plt.xlim([0, len(features.columns)])\n",
    "plt.ylim([0, len(features.columns)])\n",
    "plt.legend()\n",
    "plt.savefig(f\"figures/type_{dataset_name}_{prfs_params['graph']}_{prfs_params['alpha']}_{prfs_params['beta']}_{prfs_params['weight']}.png\", dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d21363-37d5-472b-8716-99794f311320",
   "metadata": {},
   "source": [
    "# Classifier evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d4a5db-aaad-458a-91ad-4d7a060255d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.40, random_state=42)\n",
    "\n",
    "accuracy_decision_tree = []\n",
    "accuracy_naive_bayes = []\n",
    "accuracy_svc = []\n",
    "\n",
    "decision_tree_time = []\n",
    "naive_bayes_time = []\n",
    "svc_time = []\n",
    "\n",
    "for n in range(len(features.columns)):\n",
    "    clf = DecisionTreeClassifier()\n",
    "    t1 = time.perf_counter_ns()\n",
    "    clf.fit(X_train[prfs.select(n + 1)], y_train)\n",
    "    t2 = time.perf_counter_ns()\n",
    "    decision_tree_time.append(t2 - t1)\n",
    "    accuracy_decision_tree.append(clf.score(X_test[prfs.select(n + 1)], y_test))\n",
    "    \n",
    "    clf = GaussianNB()\n",
    "    t1 = time.perf_counter_ns()\n",
    "    clf.fit(X_train[prfs.select(n + 1)], y_train)\n",
    "    t2 = time.perf_counter_ns()\n",
    "    naive_bayes_time.append(t2 - t1)\n",
    "    accuracy_naive_bayes.append(clf.score(X_test[prfs.select(n + 1)], y_test))\n",
    "    \n",
    "    clf = SVC()\n",
    "    t1 = time.perf_counter_ns()\n",
    "    clf.fit(X_train[prfs.select(n + 1)], y_train)\n",
    "    t2 = time.perf_counter_ns()\n",
    "    svc_time.append(t2 - t1)\n",
    "    accuracy_svc.append(clf.score(X_test[prfs.select(n + 1)], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf4bb6c-6467-498e-87ae-ddb9bf6431d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "plt.xlabel(r'\\textbf{Number of features}',fontsize=16)\n",
    "plt.ylabel(r'\\textbf{Accuracy}',fontsize=16)\n",
    "plt.title(f'{dataset_name} dataset', fontsize=16)\n",
    "plt.plot(range(1, len(accuracy_decision_tree) + 1), accuracy_decision_tree, marker='s', color='r', label='Decision Tree')\n",
    "plt.plot(range(1, len(accuracy_naive_bayes) + 1), accuracy_naive_bayes, marker='s', color='b', label='Naive Bayes')\n",
    "plt.plot(range(1, len(accuracy_svc) + 1), accuracy_svc, marker='s', color='g', label='SVM')\n",
    "plt.xlim([1, len(features.columns)])\n",
    "plt.ylim([0, 1])\n",
    "plt.legend()\n",
    "plt.savefig(f\"figures/accuracy_{dataset_name}_{prfs_params['graph']}_{prfs_params['alpha']}_{prfs_params['beta']}_{prfs_params['weight']}.png\", dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50de72a6-90cd-4cb2-accf-63916bb7f00f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
